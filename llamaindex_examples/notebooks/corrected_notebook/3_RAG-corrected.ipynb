{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084918c-c17d-4e14-8659-8f10ec4e4796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac1b2065-e22c-4dc2-a03f-d1f977e72206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amorvan/Documents/code_dw/llm_collection/.venv/bin/python\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "import nest_asyncio\n",
    "\n",
    "# Sanity check\n",
    "print(sys.executable)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1245a232-ae02-49df-9525-03a49945aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.core.workflow import (\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    "    StartEvent,\n",
    "    StopEvent\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    load_index_from_storage,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "import Stemmer\n",
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d13fcfb6-f294-4bb2-bbb4-6bea851f35e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 75042  100 75042    0     0   253k      0 --:--:-- --:--:-- --:--:--  254k\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!curl -o './paul_graham_essay.txt' 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "847fbf1d-db95-473d-afd4-2a8d82893248",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.2, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4741707c-d3d4-487f-991a-6959dd8901cb",
   "metadata": {},
   "source": [
    "## 1 - RAG \n",
    "\n",
    "Using the BM25 retriever system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8dd32c6-8dce-466a-a4c6-12bbb8da96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./paul_graham_essay.txt\"],\n",
    ").load_data()\n",
    "splitter = SentenceSplitter(chunk_size=256)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "retriever_top_5 = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=5,\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b33fa65-82f9-4c19-91d9-aad9fab7a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 93f9055d-64ad-4d4d-af23-9d88c8e997fe\n",
      "Text: So I'm not surprised I can't remember any programs I wrote,\n",
      "because they can't have done much. My clearest memory is of the moment\n",
      "I learned it was possible for programs not to terminate, when one of\n",
      "mine didn't. On a machine without time-sharing, this was a social as\n",
      "well as a technical error, as the data center manager's expression\n",
      "made clear....\n",
      "Score:  1.289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rez = retriever_top_5.retrieve(\"computer\")\n",
    "\n",
    "print(rez[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a7236d-e05d-43a5-9590-2e3ade02928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rez[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20291a54-7549-4fb6-9e4e-5e34225f4478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever_top_5,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "response = query_engine.query(\"Who is Paul Graham.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06904a68-04af-4704-8aa6-9846ad77bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02121cf-fdfc-482d-b665-cf094c68f630",
   "metadata": {},
   "source": [
    "## 2 - Exercise : \n",
    "\n",
    "Combine it with Workflows\n",
    "\n",
    "Create a workflow that : \n",
    "- Search for the best quote about the user query\n",
    "- Make a rap about it\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48b4327f-ab2c-4efe-a53a-6a88b62587ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_top_1 = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=1,\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ")\n",
    "\n",
    "\n",
    "class RapEvent(Event):\n",
    "    pass\n",
    "\n",
    "\n",
    "class ContextualGrahamRapWorkflow(Workflow):\n",
    "    \n",
    "    @step\n",
    "    def do(self, ev: StartEvent) -> RapEvent:\n",
    "        query = ev[\"message\"]\n",
    "        rez = retriever_top_1.retrieve(query)\n",
    "        quote = rez[0].text\n",
    "        return RapEvent(quote=quote)\n",
    "\n",
    "    @step\n",
    "    def rap(self, ev: RapEvent) -> StopEvent:\n",
    "        answer = llm.complete(f\"Make a rap on Paul Graham based on this quote {ev.quote}\")\n",
    "        return StopEvent(result=answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a69a3533-5645-4556-a065-3027db3a5a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Verse 1)  \n",
      "Yo, let me take you back to '96,  \n",
      "Paul Graham on the scene, coding slick tricks,  \n",
      "Old-fashioned site, but it was the bomb,  \n",
      "Clunky vibes, but it had that charm.  \n",
      "He said, \"If you’re curious, take a look inside,  \n",
      "This software’s got history, it’s got pride.\"  \n",
      "While the world was changing, he held his ground,  \n",
      "In a digital jungle, he was the king crowned.\n",
      "\n",
      "(Chorus)  \n",
      "Paul Graham, the visionary, breaking the mold,  \n",
      "With a mind so sharp, and a heart so bold.  \n",
      "From Y Combinator to the code he wrote,  \n",
      "In the world of tech, he’s the one we quote.\n",
      "\n",
      "(Verse 2)  \n",
      "September came, Robert felt the heat,  \n",
      "“Been grinding for a month, still can’t feel my feet.”  \n",
      "Three years later, still in the grind,  \n",
      "But Paul had a plan, he was one of a kind.  \n",
      "“Let’s recruit some talent, bring in the best,”  \n",
      "Trevor Blackwell, man, he passed the test.  \n",
      "Notecards in hand, stacking life like a pro,  \n",
      "But when it came to hacking, he stole the show.\n",
      "\n",
      "(Chorus)  \n",
      "Paul Graham, the visionary, breaking the mold,  \n",
      "With a mind so sharp, and a heart so bold.  \n",
      "From Y Combinator to the code he wrote,  \n",
      "In the world of tech, he’s the one we quote.\n",
      "\n",
      "(Bridge)  \n",
      "Independent minds, Robert and Trevor,  \n",
      "In the coding game, they were clever forever.  \n",
      "Different paths, but they shared the same dream,  \n",
      "Building the future, a powerful team.  \n",
      "From clunky to sleek, they paved the way,  \n",
      "In the world of startups, they’re here to stay.\n",
      "\n",
      "(Outro)  \n",
      "So here’s to the visionaries, the ones who create,  \n",
      "Paul Graham and his crew, they innovate.  \n",
      "With a legacy built on grit and grind,  \n",
      "In the tech revolution, they’re one of a kind.  \n",
      "Old-fashioned site, but the vision was clear,  \n",
      "In the game of life, they had no fear.  \n",
      "So let’s raise a toast to the code and the dream,  \n",
      "In the world of tech, they reign supreme!\n"
     ]
    }
   ],
   "source": [
    "w = ContextualGrahamRapWorkflow()\n",
    "\n",
    "r = await w.run(message=\"fun\")\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e94a10f6-c232-4b44-a200-c1923ed88c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='f6ef5e97-beab-4632-9c33-43d90e7cb065', embedding=None, metadata={'file_path': 'paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2025-02-20', 'last_modified_date': '2025-02-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9502a3e5-9c8b-4df9-b3f6-536ebdda7ee9', node_type='4', metadata={'file_path': 'paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2025-02-20', 'last_modified_date': '2025-02-20'}, hash='0c3c3f46cac874b495d944dfc4b920f6b68817dbbb1699ecc955d1fafb2bf87b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='1fdd3133-7f36-4d2b-8b6f-0bbf22309822', node_type='1', metadata={'file_path': 'paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2025-02-20', 'last_modified_date': '2025-02-20'}, hash='c771849a34b72881f0e93ededc5fd74fa08c8247587d2978f85e225c39c8f063'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d984628e-6950-496e-b81f-c4d6959ac042', node_type='1', metadata={}, hash='c7b47b8aaf07191a7a0a576e46f2ce0680c0e5900f6b26c14bbda20df4558806')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='(If you\\'re curious why my site looks so old-fashioned, it\\'s because it\\'s still made with this software. It may look clunky today, but in 1996 it was the last word in slick.)\\n\\nIn September, Robert rebelled. \"We\\'ve been working on this for a month,\" he said, \"and it\\'s still not done.\" This is funny in retrospect, because he would still be working on it almost 3 years later. But I decided it might be prudent to recruit more programmers, and I asked Robert who else in grad school with him was really good. He recommended Trevor Blackwell, which surprised me at first, because at that point I knew Trevor mainly for his plan to reduce everything in his life to a stack of notecards, which he carried around with him. But Rtm was right, as usual. Trevor turned out to be a frighteningly effective hacker.\\n\\nIt was a lot of fun working with Robert and Trevor. They\\'re the two most independent-minded people I know, and in completely different ways.', mimetype='text/plain', start_char_idx=29693, end_char_idx=30638, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=1.510425090789795)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rez = retriever_top_1.retrieve(\"fun\")\n",
    "rez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d616d5bf-23ee-4897-a0bb-cac5308880e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7844e41-0e22-46cc-a108-80ebdd7192a6",
   "metadata": {},
   "source": [
    "## 3 - Exercise (if time permits) \n",
    "\n",
    "Combine it with a reranker\n",
    "\n",
    "Create a workflow that : \n",
    "- Search for the best quote about the user query\n",
    "- Rerank it\n",
    "- Make a rap about it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83ec1be4-99d0-4ac2-871a-af7930323bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.postprocessor import LLMRerank\n",
    "\n",
    "\n",
    "retriever_top_5 = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=5,\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ")\n",
    "\n",
    "\n",
    "class QuotesEvent(Event):\n",
    "    pass\n",
    "\n",
    "class RapEvent(Event):\n",
    "    pass\n",
    "\n",
    "\n",
    "class RerankedGrahamRapWorkflow(Workflow):\n",
    "    \n",
    "    @step\n",
    "    def do(self, ev: StartEvent) -> QuotesEvent:\n",
    "        query = ev[\"message\"]\n",
    "        rez = retriever_top_5.retrieve(query)\n",
    "        return QuotesEvent(quotes=rez, query=query)\n",
    "\n",
    "    @step\n",
    "    def best(self, ev: QuotesEvent) -> RapEvent:\n",
    "        quotes = ev[\"quotes\"]\n",
    "        reranker = LLMRerank(\n",
    "            choice_batch_size=5,\n",
    "            top_n=5,\n",
    "        )\n",
    "        query_bundle = QueryBundle(ev.query)\n",
    "        retrieved_nodes = reranker.postprocess_nodes(\n",
    "            quotes, query_bundle\n",
    "        )\n",
    "        return RapEvent(quote=retrieved_nodes[0].text)\n",
    "\n",
    "    @step\n",
    "    def rap(self, ev: RapEvent) -> StopEvent:\n",
    "        answer = llm.complete(f\"Make a rap on Paul Graham based on this quote {ev.quote}\")\n",
    "        return StopEvent(result=answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa3860e0-6aa5-416c-9b8c-6767ffb3fc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Verse 1)  \n",
      "Yo, let me take you back to the roots of the game,  \n",
      "Paul Graham in the house, you know the name,  \n",
      "Talkin' 'bout Lisp, a model so divine,  \n",
      "An alternative to Turing, yeah, it’s one of a kind.  \n",
      "John McCarthy, the genius, he laid down the law,  \n",
      "Discovered a language, left us all in awe.  \n",
      "But it took a grad student, Steve Russell on the scene,  \n",
      "Translated that vision, made it fit for machines.  \n",
      "\n",
      "(Chorus)  \n",
      "Lisp, Lisp, the elegance flows,  \n",
      "From computation’s heart, that’s how it goes.  \n",
      "Predefined operators, minimal yet grand,  \n",
      "In the world of coding, it took a stand.  \n",
      "\n",
      "(Verse 2)  \n",
      "In sixty, McCarthy dropped the first iteration,  \n",
      "Just interpreting expressions, no complication.  \n",
      "But it was missing features, like a puzzle unsolved,  \n",
      "Had to add the pieces, let the mystery evolve.  \n",
      "Axiomatic roots, but the branches grew wide,  \n",
      "With every new addition, Lisp took a ride.  \n",
      "Power and elegance, unmatched in the race,  \n",
      "In college, Paul felt it, but couldn’t see the face.  \n",
      "\n",
      "(Chorus)  \n",
      "Lisp, Lisp, the elegance flows,  \n",
      "From computation’s heart, that’s how it goes.  \n",
      "Predefined operators, minimal yet grand,  \n",
      "In the world of coding, it took a stand.  \n",
      "\n",
      "(Bridge)  \n",
      "Now we’re coding in style, with a language so slick,  \n",
      "Recursive dreams, man, it’s a programmer’s trick.  \n",
      "From AI to startups, it’s a versatile tool,  \n",
      "Paul Graham knows the game, he’s nobody’s fool.  \n",
      "\n",
      "(Verse 3)  \n",
      "So here’s to the vision, the minds that ignite,  \n",
      "From McCarthy to Graham, they’re shining so bright.  \n",
      "In the world of tech, where the future unfolds,  \n",
      "Lisp’s legacy lives on, in the stories we’ve told.  \n",
      "So if you’re writing code, remember the past,  \n",
      "With elegance and power, make your programs last.  \n",
      "In the realm of computation, let your ideas flow,  \n",
      "Just like Paul Graham, let your genius show!  \n",
      "\n",
      "(Outro)  \n",
      "Lisp, Lisp, forever it glows,  \n",
      "In the heart of the code, that’s how it goes.  \n",
      "From the roots of the math to the stars in the sky,  \n",
      "With Paul Graham’s wisdom, we’ll always fly high!\n"
     ]
    }
   ],
   "source": [
    "w = RerankedGrahamRapWorkflow()\n",
    "\n",
    "r = await w.run(message=\"Complex computer machines\")\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb2f1a2-a9a4-4316-a45d-84f5f88f6577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b44ee-bcc7-468b-a103-e702981ca241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
