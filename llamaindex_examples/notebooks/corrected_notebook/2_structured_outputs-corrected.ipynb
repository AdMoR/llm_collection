{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3bd17d-aec3-4848-ac82-def6e2d6fa18",
   "metadata": {
    "id": "ca3bd17d-aec3-4848-ac82-def6e2d6fa18"
   },
   "source": [
    "# Examples of Structured Data Extraction \n",
    "\n",
    "\n",
    "We start with the simple syntax around LLMs, then move on to how to use it with higher-level modules like a query engine and agent.\n",
    "\n",
    "A lot of the underlying behavior around structured outputs is powered by the Pydantic Program modules. \n",
    "\n",
    "Check out the [in-depth structured outputs guide](https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6625f456-bf9c-4c89-948c-488909591855",
   "metadata": {
    "id": "6625f456-bf9c-4c89-948c-488909591855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amorvan/Documents/code_dw/llm_collection/.venv/bin/python\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import sys\n",
    "import os \n",
    "\n",
    "# Sanity check\n",
    "print(sys.executable)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ced509-b1fd-4413-9ac2-662fcfab1074",
   "metadata": {
    "id": "57ced509-b1fd-4413-9ac2-662fcfab1074"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a15e8d-45dc-4aef-93a6-8d2e97604d1e",
   "metadata": {
    "id": "72a15e8d-45dc-4aef-93a6-8d2e97604d1e"
   },
   "source": [
    "## 1. Simple Structured Extraction\n",
    "\n",
    "You can convert any LLM to a \"structured LLM\" by attaching an output class to it through `as_structured_llm`.\n",
    "\n",
    "Here we pass a simple `Album` class which contains a list of songs. We can then use the normal LLM endpoints like chat/complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63045118-74fb-4ec6-bb99-b66184eba017",
   "metadata": {
    "id": "63045118-74fb-4ec6-bb99-b66184eba017"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "class Song(BaseModel):\n",
    "    \"\"\"Data model for a song.\"\"\"\n",
    "\n",
    "    title: str = Field(\"The title of the Song\")\n",
    "    length_seconds: int = Field(\"The duration of the Song\")\n",
    "\n",
    "\n",
    "class Album(BaseModel):\n",
    "    \"\"\"Data model for an album.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    artist: str\n",
    "    songs: List[Song]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5929511-67c3-411a-925c-5155286d10cb",
   "metadata": {
    "id": "d5929511-67c3-411a-925c-5155286d10cb"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sllm = llm.as_structured_llm(output_cls=Album)\n",
    "input_msg = ChatMessage.from_str(\"Generate an example album from The Shining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a8fd46-dbc9-4973-bf70-aa0f28a7fa2d",
   "metadata": {
    "id": "d8a8fd46-dbc9-4973-bf70-aa0f28a7fa2d"
   },
   "source": [
    "#### Sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4671ba4b-d21f-4a4d-8aa8-555a679248c8",
   "metadata": {
    "id": "4671ba4b-d21f-4a4d-8aa8-555a679248c8"
   },
   "outputs": [],
   "source": [
    "output = sllm.chat([input_msg])\n",
    "# get actual object\n",
    "output_obj = output.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e29dc-b6e5-4fdb-83c4-ccb011dde2fb",
   "metadata": {
    "id": "c58e29dc-b6e5-4fdb-83c4-ccb011dde2fb",
    "outputId": "43f7d07a-ecbe-44ec-844e-4d4f5fc41dbb"
   },
   "outputs": [],
   "source": [
    "print(str(output))\n",
    "print(output_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93195eb-b62b-43eb-acad-0652f745bc64",
   "metadata": {
    "id": "a93195eb-b62b-43eb-acad-0652f745bc64"
   },
   "source": [
    "#### Async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4e582-5aa8-42e8-8d27-d9b18b8452d8",
   "metadata": {
    "id": "c8c4e582-5aa8-42e8-8d27-d9b18b8452d8",
    "outputId": "03451d59-69da-448b-8ab9-4c7ca0c48a62"
   },
   "outputs": [],
   "source": [
    "output = await sllm.achat([input_msg])\n",
    "# get actual object\n",
    "output_obj = output.raw\n",
    "print(str(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6608650-c3a9-4c09-92af-9c61376d291c",
   "metadata": {
    "id": "c6608650-c3a9-4c09-92af-9c61376d291c"
   },
   "source": [
    "#### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ab86e-b1ca-4f4c-bcb3-4c5173ed17f7",
   "metadata": {
    "id": "403ab86e-b1ca-4f4c-bcb3-4c5173ed17f7",
    "outputId": "751ebe2b-0c59-43ac-b05b-248a54fc8b72"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from pprint import pprint\n",
    "\n",
    "stream_output = sllm.stream_chat([input_msg])\n",
    "for partial_output in stream_output:\n",
    "    clear_output(wait=True)\n",
    "    pprint(partial_output.raw.dict())\n",
    "\n",
    "output_obj = partial_output.raw\n",
    "print(str(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900037f6-3fa9-4f55-bcfc-985131517f36",
   "metadata": {
    "id": "900037f6-3fa9-4f55-bcfc-985131517f36"
   },
   "source": [
    "#### Async Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c0025b-b657-42c8-a873-f51929431b8c",
   "metadata": {
    "id": "32c0025b-b657-42c8-a873-f51929431b8c",
    "outputId": "c92b123c-7299-4a78-81d6-13f8ae2c2671"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from pprint import pprint\n",
    "\n",
    "stream_output = await sllm.astream_chat([input_msg])\n",
    "async for partial_output in stream_output:\n",
    "    clear_output(wait=True)\n",
    "    pprint(partial_output.raw.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1b4bc9-56ee-4bf7-a63c-50ce0cadeeae",
   "metadata": {
    "id": "9d1b4bc9-56ee-4bf7-a63c-50ce0cadeeae"
   },
   "source": [
    "### 1.b Use the `structured_predict` Function\n",
    "\n",
    "Instead of explicitly doing `llm.as_structured_llm(...)`, every LLM class has a `structured_predict` function which allows you to more easily call the LLM with a prompt template + template variables to return a strutured output in one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488b69e-c04f-48fe-afea-7224dc79efa9",
   "metadata": {
    "id": "2488b69e-c04f-48fe-afea-7224dc79efa9",
    "outputId": "9ca81018-8a04-4745-e28e-91185cb25ef3"
   },
   "outputs": [],
   "source": [
    "# use query pipelines\n",
    "from llama_index.core.prompts import ChatPromptTemplate\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "chat_prompt_tmpl = ChatPromptTemplate(\n",
    "    message_templates=[\n",
    "        ChatMessage.from_str(\n",
    "            \"Generate an example album from {movie_name}\", role=\"user\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "album = llm.structured_predict(\n",
    "    Album, chat_prompt_tmpl, movie_name=\"Lord of the Rings\"\n",
    ")\n",
    "album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72151ca-b471-41ad-a762-f483ca341d9b",
   "metadata": {
    "id": "c72151ca-b471-41ad-a762-f483ca341d9b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1f81633-cdcb-4e8d-a43f-43b699a0cf01",
   "metadata": {
    "id": "f1f81633-cdcb-4e8d-a43f-43b699a0cf01"
   },
   "source": [
    "## 2. Exercise\n",
    "\n",
    "Tell a story step by step. \n",
    "\n",
    "For each part of the story, there should be \n",
    "- The story part\n",
    "- A description of the image that will go with this part of the story\n",
    "\n",
    "\n",
    "Do it with a Pydantic class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2745476-02be-4f2a-86ff-5386aae1260d",
   "metadata": {
    "id": "d2745476-02be-4f2a-86ff-5386aae1260d",
    "outputId": "b2db18c9-9c9b-40e0-aa69-9f69536b7245"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class StoryChunk(BaseModel):\n",
    "    \"\"\"Data model for a chunk of a  story\"\"\"\n",
    "    text: str = Field(\"The text of the story chunk\")\n",
    "    image_description: str = Field(\"The depiction of the story\")\n",
    "\n",
    "\n",
    "class Story(BaseModel):\n",
    "    \"\"\"A story has several cunk made of a text and an image.\"\"\"\n",
    "    chunks: List[StoryChunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9509b85e-0091-4fc0-8649-5a3d83d6dcf0",
   "metadata": {
    "id": "9509b85e-0091-4fc0-8649-5a3d83d6dcf0",
    "outputId": "7ea8f6b5-992d-4512-c66a-f331f908c368"
   },
   "outputs": [],
   "source": [
    "sllm = llm.as_structured_llm(output_cls=Story)\n",
    "input_msg = ChatMessage.from_str(\"Generate a story about a bird\")\n",
    "\n",
    "story = sllm.complete(input_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee757df9-0491-46ba-b369-d8cdf1b7d74f",
   "metadata": {
    "id": "ee757df9-0491-46ba-b369-d8cdf1b7d74f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StoryChunk(text='Once upon a time in a small village, there lived a kind-hearted girl named Lily. She loved to help others and spent her days tending to the village garden, where flowers bloomed in vibrant colors.', image_description='A picturesque village garden filled with colorful flowers and a girl tending to them.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story.raw.chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e318de5-7c7b-49a2-8de6-140f16b07d8f",
   "metadata": {
    "id": "1e318de5-7c7b-49a2-8de6-140f16b07d8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StoryChunk(text='One day, while watering the plants, Lily discovered a tiny, injured bird lying on the ground. Without hesitation, she gently picked it up and took it home to care for it.', image_description='A close-up of a girl holding a small injured bird in her hands, looking concerned.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story.raw.chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df8be76-53f6-4e81-8b22-7281e0ac35eb",
   "metadata": {
    "id": "6df8be76-53f6-4e81-8b22-7281e0ac35eb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e52dfc-31a5-41bf-972c-284c8a3263d3",
   "metadata": {
    "id": "d3e52dfc-31a5-41bf-972c-284c8a3263d3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2d822-50cb-4eca-9c14-661c47bb70b7",
   "metadata": {
    "id": "31c2d822-50cb-4eca-9c14-661c47bb70b7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc211576-7101-4d1d-a874-eaf1ba5ad7a5",
   "metadata": {
    "id": "bc211576-7101-4d1d-a874-eaf1ba5ad7a5",
    "outputId": "5744d7c8-16a5-4909-b74f-d31429e8ad73"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340bc8a8-7460-4683-bf2e-518c35ba68af",
   "metadata": {
    "id": "340bc8a8-7460-4683-bf2e-518c35ba68af",
    "outputId": "0e1b32c7-0414-4b44-91dd-2d67c89d6e7e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e3a13-9c93-4980-ba3e-eedf54ec0fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
