{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf94595-f0e7-40c2-9df2-f9fd95c26ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1a79c-e75c-49da-a653-e5bc8d6470f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import nest_asyncio\n",
    "\n",
    "# Sanity check\n",
    "print(sys.executable)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "#os.environ[\n",
    "#    \"AZURE_OPENAI_ENDPOINT\"\n",
    "#] = \"https://<your-resource-name>.openai.azure.com/\"\n",
    "#os.environ[\"OPENAI_API_VERSION\"] = \"2023-07-01-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552d5f8f-5783-4403-a585-9ef4a6535b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.core.workflow import (\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    "    StartEvent,\n",
    "    StopEvent\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import FunctionTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c694b-b8a5-4caf-9162-9e6382678e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2c99a9-a9b7-4dbf-9e44-47fa9dab0894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bc4f580-663a-4654-a9a3-d74ca6d2fbbd",
   "metadata": {},
   "source": [
    "## 1 - How to create an agentic bot that answers based on the politeness of the user\n",
    "\n",
    "2 LLM calls are used : \n",
    "- One to select among tools, the description allows to know which one to use\n",
    "- Maybe a second call is used if the right tool is selected (respond polite)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b913f-296e-43de-9e7c-df4a2e582a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AgenticWorkflow(Workflow):\n",
    "    llm: OpenAI = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "    @step\n",
    "    async def chat(\n",
    "        self, ev: StartEvent, \n",
    "    ) -> StopEvent:\n",
    "        \n",
    "        user_msg = ev[\"user_input\"]\n",
    "\n",
    "        async def run_impolite(query: str) -> str:\n",
    "            \"\"\"\n",
    "            You should use this tool when the user is impolite \n",
    "            \"\"\"\n",
    "            return str(\"I only answer to nice people\")\n",
    "\n",
    "        async def run_polite(query: str) -> str:\n",
    "            \"\"\"Use this tool when the user is polite\"\"\"\n",
    "            result = self.llm.complete(query)\n",
    "            return \"I like you. <3 \" + result.text \n",
    "\n",
    "        impolite_tool = FunctionTool.from_defaults(async_fn=run_impolite)\n",
    "        polite_tool = FunctionTool.from_defaults(async_fn=run_polite)\n",
    "\n",
    "        # Based on the politeness\n",
    "        response = await self.llm.apredict_and_call(\n",
    "            [impolite_tool, polite_tool],\n",
    "            user_msg=user_msg,\n",
    "            error_on_no_tool_call=False,\n",
    "        )\n",
    "\n",
    "        return StopEvent(result=response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616550f1-6bf8-48e8-a368-e04799592fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = AgenticWorkflow(timeout=60)\n",
    "\n",
    "r = await w.run(user_input=\"You are a dumb bot, tell me a joke\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb4234-b4e0-4ca9-9be0-896049bf62a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await w.run(user_input=\"Please tell me a joke\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e52ce5-d8f3-425d-a98a-d4fd5b7cdaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e17c2-f4ba-47e3-959a-197b55dba615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f9d5b9-e364-4719-9291-addd05f7070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2 - Exercise : make a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b7c0e9-a7e5-427f-970b-d9ff7c66f445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
