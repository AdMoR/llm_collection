{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084918c-c17d-4e14-8659-8f10ec4e4796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac1b2065-e22c-4dc2-a03f-d1f977e72206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amor/Documents/code_dw/human_in_the_loop_workflow_demo/venv/bin/python3.11\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os \n",
    "import nest_asyncio\n",
    "\n",
    "# Sanity check\n",
    "print(sys.executable)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\"\n",
    "#os.environ[\n",
    "#    \"AZURE_OPENAI_ENDPOINT\"\n",
    "#] = \"https://<your-resource-name>.openai.azure.com/\"\n",
    "#os.environ[\"OPENAI_API_VERSION\"] = \"2023-07-01-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1245a232-ae02-49df-9525-03a49945aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.core.workflow import (\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    "    StartEvent,\n",
    "    StopEvent\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    load_index_from_storage,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "import Stemmer\n",
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d13fcfb6-f294-4bb2-bbb4-6bea851f35e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-01 15:58:57--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8002::154, 2606:50c0:8003::154, 2606:50c0:8000::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8002::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘./paul_graham_essay.txt’\n",
      "\n",
      "./paul_graham_essay 100%[===================>]  73,28K  --.-KB/s    in 0,02s   \n",
      "\n",
      "2024-12-01 15:58:57 (3,71 MB/s) - ‘./paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O './paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847fbf1d-db95-473d-afd4-2a8d82893248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4741707c-d3d4-487f-991a-6959dd8901cb",
   "metadata": {},
   "source": [
    "## 1 - RAG \n",
    "\n",
    "Using the BM25 retriever system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8dd32c6-8dce-466a-a4c6-12bbb8da96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./paul_graham_essay.txt\"],\n",
    ").load_data()\n",
    "splitter = SentenceSplitter(chunk_size=256)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "retriever_top_5 = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=5,\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"english\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b33fa65-82f9-4c19-91d9-aad9fab7a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 9f5abd83-5775-4820-a5d5-e64d47be56e9\n",
      "Text: So I'm not surprised I can't remember any programs I wrote,\n",
      "because they can't have done much. My clearest memory is of the moment\n",
      "I learned it was possible for programs not to terminate, when one of\n",
      "mine didn't. On a machine without time-sharing, this was a social as\n",
      "well as a technical error, as the data center manager's expression\n",
      "made clear....\n",
      "Score:  1.289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rez = retriever_top_5.retrieve(\"computer\")\n",
    "\n",
    "print(rez[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9a7236d-e05d-43a5-9590-2e3ade02928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was meant to be a formal model of computation, an alternative to the Turing machine. If you want to write an interpreter for a language in itself, what's the minimum set of predefined operators you need? The Lisp that John McCarthy invented, or more accurately discovered, is an answer to that question. [19]\n",
      "\n",
      "McCarthy didn't realize this Lisp could even be used to program computers till his grad student Steve Russell suggested it. Russell translated McCarthy's interpreter into IBM 704 machine language, and from that point Lisp started also to be a programming language in the ordinary sense. But its origins as a model of computation gave it a power and elegance that other languages couldn't match. It was this that attracted me in college, though I didn't understand why at the time.\n",
      "\n",
      "McCarthy's 1960 Lisp did nothing more than interpret Lisp expressions. It was missing a lot of things you'd want in a programming language. So these had to be added, and when they were, they weren't defined using McCarthy's original axiomatic approach. That wouldn't have been feasible at the time.\n"
     ]
    }
   ],
   "source": [
    "print(rez[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20291a54-7549-4fb6-9e4e-5e34225f4478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever_top_5,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "response = query_engine.query(\"Who is Paul Graham.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06904a68-04af-4704-8aa6-9846ad77bba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paul Graham is a hardworking individual who dedicated a significant amount of time and effort to working on a project called Bel. He faced challenges while working on this project, such as wrestling with bugs and dealing with complex problems. Despite these difficulties, he found the work satisfying and rewarding. Additionally, he is known for his involvement in creating the Summer Founders Program, which attracted a large number of applicants, including notable individuals like Justin Kan, Emmett Shear, Aaron Swartz, and Sam Altman.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02121cf-fdfc-482d-b665-cf094c68f630",
   "metadata": {},
   "source": [
    "## 2 - Exercise : \n",
    "\n",
    "Combine it with Workflows\n",
    "\n",
    "Create a workflow that : \n",
    "- Search for the best quote about the user query\n",
    "- Make a rap about it\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b4327f-ab2c-4efe-a53a-6a88b62587ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ContextualGrahamRapWorkflow(Workflow):\n",
    "    \n",
    "    @step\n",
    "    def do(self, ev: StartEvent) -> StopEvent:\n",
    "        return StopEvent()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a69a3533-5645-4556-a065-3027db3a5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ContextualGrahamRapWorkflow()\n",
    "\n",
    "r = await w.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a10f6-c232-4b44-a200-c1923ed88c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
